# Uptick Coding - Web Crawler System

## ğŸš€ Overview

A high-performance web crawler system optimized for domain analysis and content extraction. Built with Python and deployed on Modal's cloud infrastructure for scalable, concurrent execution.

## âœ¨ Key Features

- **3-Container Concurrent Execution** - True parallel processing using Modal's `.map()` method
- **Cost Optimized** - 49% cost savings with 3x faster completion
- **Scalable Architecture** - Easy to scale from 3 to 10+ containers
- **Batch Processing** - Automated batch execution with progress tracking
- **Volume Storage** - Persistent results storage in Modal volumes

## ğŸ—ï¸ Architecture

### Concurrent Execution Setup

- **3 containers** running simultaneously
- **Each container**: 1 CPU + 2GB RAM (optimized for web crawling)
- **Domain distribution**: Automatically split across containers
- **True parallelism**: All containers launch simultaneously using Modal's `.map()` method

### Performance Benefits

- **3x faster completion** compared to single container
- **49% cost savings** compared to single large container
- **Better resource utilization** (no idle CPU/memory)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Modal CLI: `pip install modal`
- Modal account configured

### Deploy and Run

```bash
# Deploy the Modal app
modal deploy crawler/modal_deploy_real.py

# Test with 30 domains (3 containers Ã— 10 domains each)
modal run crawler/modal_deploy_real.py --total-domains 30

# Run with 1000 domains (3 containers Ã— 333 domains each)
modal run crawler/modal_deploy_real.py --total-domains 1000
```

### Batch Processing

```bash
# Show status and help
./run_batch_crawler.sh

# Run next batch
./run_batch_crawler.sh --next

# Run specific batch
./run_batch_crawler.sh 3

# Deploy app
./run_batch_crawler.sh --deploy
```

## ğŸ“Š Usage Examples

### Basic Execution

```bash
# Test run with 30 domains
modal run crawler/modal_deploy_real.py --total-domains 30
```

### Production Scale

```bash
# Process 5000 domains (3 containers Ã— 1667 domains each)
modal run crawler/modal_deploy_real.py --total-domains 5000
```

### Programmatic Usage

```python
import modal

app = modal.App('uptick-crawler-real')

# Run concurrent crawler
result = app.crawl_domains_concurrent.remote(
    total_domains=1000,
    domain_column="Company Domain Name",
    id_column="Record ID"
)

print(f"Containers launched: {result['container_count']}")
print(f"Status: {result['status']}")
```

## ğŸ“ Project Structure

```
Uptick-Coding/
â”œâ”€â”€ crawler/                          # Core crawler logic
â”‚   â”œâ”€â”€ modal_deploy_real.py         # Modal deployment with concurrent execution
â”‚   â”œâ”€â”€ run_crawl.py                 # Main crawling engine
â”‚   â””â”€â”€ config.json                  # Crawler configuration
â”œâ”€â”€ run_batch_crawler.sh             # Batch processing script
â”œâ”€â”€ uptick-csvs/                     # Input CSV files
â”œâ”€â”€ 5.-Docs/                         # Documentation
â”‚   â”œâ”€â”€ MODAL_CONCURRENT_SETUP.md    # Concurrent execution guide
â”‚   â”œâ”€â”€ modal-deployment-documentation.md  # Deployment details
â”‚   â””â”€â”€ crawler-documentation.md     # Crawler system docs
â””â”€â”€ crawl-runs/                      # Output results
```

## ğŸ”§ Configuration

### Resource Allocation

- **Container specs**: 1 CPU + 2GB RAM per container
- **Total resources**: 3 CPU + 6GB RAM (distributed)
- **Timeout**: 5 hours per container
- **Optimized for**: I/O-bound web crawling operations

### Domain Processing

- **Batch size**: 1000 domains per batch
- **Total domains**: 10,097 domains
- **Total batches**: 11 batches
- **Each batch**: Uses 3-container concurrent execution

## ğŸ“ˆ Monitoring

### Modal Dashboard

- **Real-time monitoring** of all 3 containers
- **Resource usage** tracking (CPU, memory)
- **Execution logs** and error reporting
- **Container status** and completion tracking

### Log Analysis

The system provides detailed logging for each execution:

```
ğŸš€ Starting CONCURRENT crawl with 3 containers
ğŸ’» Each container: 1 CPU + 2GB RAM
ğŸ“Š Total domains: 1000
ğŸ“¦ Domains per container: 333
ğŸ”„ Launching 3 containers using Modal's .map() method!
âœ… Container 1 completed successfully: 333 domains
âœ… Container 2 completed successfully: 333 domains
âœ… Container 3 completed successfully: 334 domains
```

## ğŸ”® Future Enhancements

### HTTP API Integration

The current implementation is ready for HTTP API conversion:

- **Change decorator**: `@app.local_entrypoint()` â†’ `@modal.fastapi_endpoint()`
- **Same core logic**: Uses `.map()` method for parallel execution
- **Results returned**: Complete data from all containers

### Scaling Options

- **Increase containers**: Easy to scale to 5, 10, or more containers
- **Dynamic scaling**: Based on workload and performance requirements
- **Cost optimization**: Balance between speed and cost

## ğŸ› Troubleshooting

### Common Issues

1. **Container startup failures**

   - Check Modal app deployment: `modal app list`
   - Verify resource allocation limits
   - Review container logs for errors

2. **Performance issues**
   - Ensure all 3 containers are running
   - Check domain distribution balance
   - Monitor resource utilization

### Debug Commands

```bash
# Check app status
modal app list

# View app logs
modal app logs uptick-crawler-real

# Check function calls
modal function calls uptick-crawler-real::crawl_domains_concurrent
```

## ğŸ“š Documentation

- **[MODAL_CONCURRENT_SETUP.md](5.-Docs/MODAL_CONCURRENT_SETUP.md)** - Concurrent execution guide
- **[modal-deployment-documentation.md](5.-Docs/modal-deployment-documentation.md)** - Deployment details
- **[crawler-documentation.md](5.-Docs/crawler-documentation.md)** - System architecture
- **[scoring-documentation.md](5.-Docs/scoring-documentation.md)** - Scoring system

## ğŸ¯ Summary

The Uptick crawler system provides:

- âœ… **True parallel execution** using Modal's `.map()` method
- âœ… **3x performance improvement** with 3 containers
- âœ… **49% cost savings** compared to single container
- âœ… **Better resource utilization** and scalability
- âœ… **Future-ready** for HTTP API integration

This represents a significant improvement over previous sequential execution approaches, delivering faster results at lower cost.

---

_Last Updated: January 2025_  
_Architecture: 3-container concurrent execution using Modal's .map() method_
